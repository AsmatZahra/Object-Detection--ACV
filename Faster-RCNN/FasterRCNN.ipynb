{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FasterRCNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUh4ONY9KtOD",
        "colab_type": "code",
        "outputId": "54c4f2b9-0425-4c8b-a45d-03563776759e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqRvWqgfK3Px",
        "colab_type": "code",
        "outputId": "c1c9a91b-57d7-460f-ebda-2f3ce05ca01d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/acv assignments/assignment 2 modified/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/acv assignments/assignment 2 modified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zksf2J_1Mo0N",
        "colab_type": "code",
        "outputId": "be650497-b858-401a-aeea-edf2975b9723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " FasterR-CNN   FasterR-CNN2   RetinaNet  'SIMS dataset'  'SIMS dataset2'   YOLO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MqmlkxrLK7p",
        "colab_type": "code",
        "outputId": "3f4eaaeb-b324-4e08-bd8a-1fe152139858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPRdvAYLLRTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#zip_path = '/content/drive/My Drive/Colab Notebooks/acv assignments/assignment 2 modified/SIMS dataset/'\n",
        "#!unzip '$zip_path' -d ./data/\n",
        "!unzip -q 'SIMS dataset2/images.zip' -d data\n",
        "!unzip -q 'SIMS dataset2/Annotations_in_3_formats.zip' -d data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NksQxXUfNBpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, csv, PIL\n",
        "\n",
        "def create_csv(txt_path, output_path, class_mapping):\n",
        "  \"\"\"\n",
        "  Creates a csv file that can be used with keras-retinanet csv generator\n",
        "  (Dependencies: [os, csv, PIL])\n",
        "  \"\"\"\n",
        "  # A subfunction to read annotations file\n",
        "  def read_ann(ann_path):\n",
        "    with open(ann_path, 'r') as f:\n",
        "      lines = f.readlines()\n",
        "    return lines\n",
        "\n",
        "  # A subfunction to convert percentage centre \n",
        "  # co-ordinates to x1, y1, x2, y2 absolute co-ordinates\n",
        "  def get_abs_coord(coords, im_w, im_h):\n",
        "    n_coords = coords.copy()\n",
        "    n_coords[0] = (coords[0] - (coords[2]/2)) * im_w\n",
        "    n_coords[2] = n_coords[0] + (coords[2] * im_w)\n",
        "    n_coords[1] = (coords[1] - (coords[3]/2)) * im_h\n",
        "    n_coords[3] = n_coords[1] + (coords[3] * im_h)\n",
        "\n",
        "    return list(map(int, n_coords))\n",
        "\n",
        "  # Class ID to name mapping\n",
        "  id_to_name = class_mapping\n",
        "\n",
        "  # create_csv continues.\n",
        "  # A bit of mangling with the path\n",
        "  root = '/content/drive/My Drive/Colab Notebooks/acv assignments/assignment 2 modified/FasterR-CNN2/data'\n",
        "  # CSV list to keep track of the lines needed to be written to the csv\n",
        "  csv_list = []\n",
        "  with open(txt_path, 'r') as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "      # Get images path\n",
        "      im_path = line.strip()\n",
        "      abs_im_path = root + '/' + \"/\".join(line.strip().split('/')[1:])\n",
        "      # Get path of annotations for the image\n",
        "      im_txt_path = os.path.splitext(abs_im_path)[0] + '.txt'\n",
        "      # Get the annotations\n",
        "      anns = read_ann(im_txt_path)\n",
        "      for ann in anns:\n",
        "        items = ann.strip().split(' ')\n",
        "        c_id, bb = int(items[0]), list(map(float, items[1:]))\n",
        "        # Get the size of the image\n",
        "        w, h = PIL.Image.open(abs_im_path).size\n",
        "        # Get absolute co-ordinates\n",
        "        bb = get_abs_coord(bb, w, h)\n",
        "        # Row for csv file, converting x,y,w,h to x,y,x1, y1\n",
        "        csv_list.append([abs_im_path, *bb, id_to_name[c_id]])\n",
        "      # Read next line\n",
        "      line = f.readline()\n",
        "\n",
        "    with open(output_path, 'w', newline=\"\") as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerows(csv_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqBstSkNns_i",
        "colab_type": "code",
        "outputId": "71e5d430-518c-479f-a084-bc8c41e79667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/acv assignments/assignment 2 modified/FasterR-CNN2/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/acv assignments/assignment 2 modified/FasterR-CNN2\n",
            "config.pickle  LICENSE\t\t README.md\t   train_frcnn.py\n",
            "data\t       measure_map.py\t requirements.txt  Untitled.ipynb\n",
            "keras_frcnn    model_frcnn.hdf5  test_frcnn.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSjftrrGszjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "3 41am"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GzFdNoanAY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_mapping = ['Car', 'Truck', 'Van', 'LongVehicle', 'Bus', \n",
        "                'Airliner', 'Propeller Aircraft', 'Trainer Aircraft', 'Chartered Aircraft',\n",
        "                'Fighter Aircraft', 'Others', 'Stair Truck', 'Pushback Truck',\n",
        "                'Helicopter', 'Boat']\n",
        "class_mapping = dict(enumerate(class_mapping))\n",
        "\n",
        "create_csv('data/training.txt', 'data/training.csv', class_mapping)\n",
        "create_csv('data/test.txt', 'data/test.csv', class_mapping)\n",
        "create_csv('data/validation.txt', 'data/validation.csv', class_mapping)\n",
        "\n",
        "class_csv = list(map(lambda x: (x[1], x[0]), class_mapping.items()))\n",
        "\n",
        "with open('data/classes.csv', 'w', newline=\"\") as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerows(class_csv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdRdFTqdp_2g",
        "colab_type": "code",
        "outputId": "ac59f991-53c5-4de2-bbe4-b6bb04fc847f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "!git clone https://github.com/kbardool/keras-frcnn\n",
        "!mv keras-frcnn/* .\n",
        "!rm -r keras-frcnn\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-frcnn'...\n",
            "remote: Enumerating objects: 589, done.\u001b[K\n",
            "remote: Total 589 (delta 0), reused 0 (delta 0), pack-reused 589\u001b[K\n",
            "Receiving objects: 100% (589/589), 173.38 KiB | 799.00 KiB/s, done.\n",
            "Resolving deltas: 100% (402/402), done.\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.10.0)\n",
            "Collecting Keras==2.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/36/fc4b247ec139ad9cc6f223ed10729d85401fc5203703c23457794f9bfe60/Keras-2.0.3.tar.gz (196kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.18.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.1.2.30)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from Keras==2.0.3->-r requirements.txt (line 2)) (1.0.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.0.3->-r requirements.txt (line 2)) (3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 5)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->Keras==2.0.3->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 5)) (0.15.0)\n",
            "Building wheels for collected packages: Keras\n",
            "  Building wheel for Keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Keras: filename=Keras-2.0.3-cp36-none-any.whl size=232962 sha256=f9ff6634d40cf93b9b2cc828d6ae19f32737b9140469fcfc031c7c2b8c0292dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/fb/de/faea9e49d563a35f198c6dede7f9260074b5beb8f9bffaaaa1\n",
            "Successfully built Keras\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.0.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed Keras-2.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_skhvHnpofaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "5 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihj661YP--AO",
        "colab_type": "code",
        "outputId": "4ee042eb-20b6-4f72-efb4-fd5f69dc532c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train_frcnn.py -o simple -p data/training.csv --num_epochs 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Parsing annotation files\n",
            "Training images per class:\n",
            "{'Airliner': 756,\n",
            " 'Boat': 3965,\n",
            " 'Bus': 1337,\n",
            " 'Car': 8861,\n",
            " 'Chartered Aircraft': 485,\n",
            " 'Fighter Aircraft': 41,\n",
            " 'Helicopter': 44,\n",
            " 'LongVehicle': 1241,\n",
            " 'Others': 595,\n",
            " 'Propeller Aircraft': 154,\n",
            " 'Pushback Truck': 141,\n",
            " 'Stair Truck': 317,\n",
            " 'Trainer Aircraft': 490,\n",
            " 'Truck': 1936,\n",
            " 'Van': 3510,\n",
            " 'bg': 0}\n",
            "Num classes (including bg) = 16\n",
            "Config has been written to config.pickle, and can be loaded when testing to ensure correct results\n",
            "Num train samples 2706\n",
            "Num val samples 527\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:47: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:351: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3176: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3043: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3153: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/acv assignments/assignment 2 modified/FasterR-CNN2/keras_frcnn/RoiPoolingConv.py:105: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3045: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1064: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "loading weights from resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "Could not load pretrained model weights. Weights can be found in the keras application folder \t\thttps://github.com/fchollet/keras/tree/master/keras/applications\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2642: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1046: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "Starting training\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:768: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:521: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:764: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:141: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:146: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:151: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-05-21 00:29:07.912525: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-05-21 00:29:07.964501: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21bf2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-21 00:29:07.964541: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-21 00:29:07.971309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-21 00:29:08.169607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 00:29:08.170722: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21bf480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-21 00:29:08.170797: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-05-21 00:29:08.172251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 00:29:08.173076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-21 00:29:08.173467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-21 00:29:08.427554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-21 00:29:08.560561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-21 00:29:08.585708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-21 00:29:08.849908: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-21 00:29:08.878776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-21 00:29:09.383175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-21 00:29:09.383470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 00:29:09.384420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 00:29:09.385254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-21 00:29:09.391787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-21 00:29:09.393712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-21 00:29:09.393762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-21 00:29:09.393780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-21 00:29:09.395074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 00:29:09.396166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 00:29:09.396928: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-21 00:29:09.396988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:300: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:308: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "2020-05-21 00:29:19.137506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-21 00:29:23.574426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            " 997/1000 [============================>.] - ETA: 2s - rpn_cls: 0.5998 - rpn_regr: 0.4916 - detector_cls: 0.9796 - detector_regr: 0.4626Average number of overlapping bounding boxes from RPN = 7.477 for 1000 previous iterations\n",
            "1000/1000 [==============================] - 934s - rpn_cls: 0.5993 - rpn_regr: 0.4908 - detector_cls: 0.9796 - detector_regr: 0.4625   \n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.504486540378863\n",
            "Classifier accuracy for bounding boxes from RPN: 0.784125\n",
            "Loss RPN classifier: 0.5992942871525884\n",
            "Loss RPN regression: 0.4907841827720404\n",
            "Loss Detector classifier: 0.979613577674143\n",
            "Loss Detector regression: 0.46254497598111627\n",
            "Elapsed time: 934.6735510826111\n",
            "Total loss decreased from inf to 2.532237023579888, saving weights\n",
            "Epoch 2/2\n",
            " 993/1000 [============================>.] - ETA: 6s - rpn_cls: 0.3827 - rpn_regr: 0.3915 - detector_cls: 0.9976 - detector_regr: 0.4277Average number of overlapping bounding boxes from RPN = 10.359 for 1000 previous iterations\n",
            "1000/1000 [==============================] - 905s - rpn_cls: 0.3820 - rpn_regr: 0.3916 - detector_cls: 0.9985 - detector_regr: 0.4282   \n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 10.359561752988048\n",
            "Classifier accuracy for bounding boxes from RPN: 0.72825\n",
            "Loss RPN classifier: 0.38195187984200313\n",
            "Loss RPN regression: 0.391553374920506\n",
            "Loss Detector classifier: 0.9984857808286324\n",
            "Loss Detector regression: 0.42818988127447666\n",
            "Elapsed time: 928.1570031642914\n",
            "Total loss decreased from 2.532237023579888 to 2.200180916865618, saving weights\n",
            "Training complete, exiting.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPq2ZFpFyicz",
        "colab_type": "code",
        "outputId": "44539a21-68c8-40b7-91c1-48841d1fb867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/acv assignments/assignment 2 modified/FasterR-CNN2/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/acv assignments/assignment 2 modified/FasterR-CNN2\n",
            "annotations    images\t       model_frcnn.hdf5  test_frcnn.py\t training.txt\n",
            "classes.csv    keras_frcnn     README.md\t test.txt\t Untitled.ipynb\n",
            "config.pickle  LICENSE\t       requirements.txt  train_frcnn.py  validation.csv\n",
            "data\t       measure_map.py  test.csv\t\t training.csv\t validation.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K65hQQkx8cE",
        "colab_type": "code",
        "outputId": "49a8360f-2373-4766-acc8-f228bdf54016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python test_frcnn.py -p /images/0001.jpg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "{0: 'Car', 1: 'Chartered Aircraft', 2: 'Airliner', 3: 'Van', 4: 'Others', 5: 'Stair Truck', 6: 'Pushback Truck', 7: 'Bus', 8: 'Truck', 9: 'Helicopter', 10: 'Propeller Aircraft', 11: 'Boat', 12: 'Trainer Aircraft', 13: 'LongVehicle', 14: 'Fighter Aircraft', 15: 'bg'}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:47: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:351: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3176: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3043: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3153: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/acv assignments/assignment 2 modified/FasterR-CNN2/keras_frcnn/RoiPoolingConv.py:105: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3045: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1064: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "Loading weights from ./model_frcnn.hdf5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:141: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:146: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:151: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-05-21 01:34:46.144466: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-05-21 01:34:46.144746: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaa661c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-21 01:34:46.144779: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-21 01:34:46.147069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-21 01:34:46.251126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 01:34:46.252455: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaa66380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-21 01:34:46.252495: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-05-21 01:34:46.252718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 01:34:46.253823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-21 01:34:46.254215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-21 01:34:46.256070: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-21 01:34:46.257822: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-21 01:34:46.258166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-21 01:34:46.259791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-21 01:34:46.260619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-21 01:34:46.263836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-21 01:34:46.263977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 01:34:46.264892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 01:34:46.265722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-21 01:34:46.265793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-21 01:34:46.267237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-21 01:34:46.267267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-21 01:34:46.267282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-21 01:34:46.267431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 01:34:46.268320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-21 01:34:46.269209: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-21 01:34:46.269302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:300: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:308: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"test_frcnn.py\", line 150, in <module>\n",
            "    for idx, img_name in enumerate(sorted(os.listdir(img_path))):\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/images/0001.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir_upQHIx4ec",
        "colab_type": "code",
        "outputId": "c969a7b1-b697-46ad-ff3f-6c04dcde0d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "!python measure_map.py -o simple -p data/validation.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Traceback (most recent call last):\n",
            "  File \"measure_map.py\", line 106, in <module>\n",
            "    C = pickle.load(f_in)\n",
            "  File \"/usr/lib/python3.6/codecs.py\", line 321, in decode\n",
            "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
            "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}